# k8s/values/alloy.yaml
alloy:
  configMap:
    create: true
    content: |
      
      // ==============================================================================
      // 1. SYSTEM PIPELINE (Tenant: platform-k8s)
      //    Target: Cluster Infrastructure, Nodes, System Logs, Events
      // ==============================================================================

      // --- METRICS: Node Exporter (Host Metrics) ---
      prometheus.exporter.unix "node_metrics" { }

      prometheus.scrape "node_scraper" {
        targets    = prometheus.exporter.unix.node_metrics.targets
        forward_to = [prometheus.remote_write.mimir_system.receiver]
      }

      // --- METRICS: Kubelet/cAdvisor (Cluster Health/Container Metrics) ---
      discovery.kubernetes "nodes" {
        role = "node"
      }

      prometheus.scrape "kubelet_scraper" {
        targets    = discovery.kubernetes.nodes.targets
        scheme     = "https"
        tls_config {
          ca_file = "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
          insecure_skip_verify = true
        }
        bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
        forward_to = [prometheus.remote_write.mimir_system.receiver]
      }

      // --- LOGS: System Pods (kube-system, argocd) ---
      discovery.kubernetes "pods" {
        role = "pod"
      }

      discovery.relabel "logs_k8s" {
        targets = discovery.kubernetes.pods.targets
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          action = "keep"
          regex = "kube-system|argocd-system" 
        }
      }

      loki.source.kubernetes "pod_logs_k8s" {
        targets    = discovery.relabel.logs_k8s.output
        forward_to = [loki.write.loki_system.receiver]
      }

      // --- LOGS: Kubernetes Events ---
      loki.source.kubernetes_events "cluster_events" {
        job_name   = "integrations/kubernetes/eventhandler"
        forward_to = [loki.write.loki_system.receiver]
      }

      // --- EXPORTERS (platform-k8s) ---
      prometheus.remote_write "mimir_system" {
        endpoint {
          url = "http://mimir-nginx.observability-prd.svc:80/api/v1/push"
          headers = { "X-Scope-OrgID" = "platform-k8s" }
        }
      }

      loki.write "loki_system" {
        endpoint {
          url = "http://loki-gateway.observability-prd.svc:80/loki/api/v1/push"
          headers = { "X-Scope-OrgID" = "platform-k8s" }
        }
      }

      // ==============================================================================
      // 2. OBSERVABILITY PIPELINE (Tenant: platform-obs)
      //    Target: The LGTM Stack itself (observability-prd namespace)
      // ==============================================================================

      // --- LOGS: Observability Namespace ---
      discovery.relabel "logs_obs" {
        targets = discovery.kubernetes.pods.targets
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          action = "keep"
          regex = "observability-prd"
        }
      }

      loki.source.kubernetes "pod_logs_obs" {
        targets    = discovery.relabel.logs_obs.output
        forward_to = [loki.write.loki_obs.receiver]
      }

      // --- EXPORTERS (platform-obs) ---
      loki.write "loki_obs" {
        endpoint {
          url = "http://loki-gateway.observability-prd.svc:80/loki/api/v1/push"
          headers = { "X-Scope-OrgID" = "platform-obs" }
        }
      }

      // ==============================================================================
      // 3. SHOP PIPELINE (Tenant: devteam-1)
      //    Target: Application Data (OTLP from OTel Demo)
      // ==============================================================================

      // --- RECEIVER (OTLP) ---
      otelcol.receiver.otlp "shop_receiver" {
        grpc { endpoint = "0.0.0.0:4317" }
        http { endpoint = "0.0.0.0:4318" }

        output {
          metrics = [otelcol.processor.batch.shop_batch.input]
          logs    = [otelcol.processor.batch.shop_batch.input]
          traces  = [otelcol.processor.batch.shop_batch.input]
        }
      }

      // --- PROCESSOR ---
      otelcol.processor.batch "shop_batch" {
        output {
          metrics = [otelcol.exporter.prometheus.mimir_shop_converter.input]
          logs    = [otelcol.exporter.loki.loki_shop.input]
          traces  = [otelcol.exporter.otlp.tempo_shop.input]
        }
      }

      // --- EXPORTERS (devteam-1) ---

      // 1. Traces -> Tempo
      otelcol.exporter.otlp "tempo_shop" {
        client {
          endpoint = "tempo.observability-prd.svc:4317"
          tls { insecure = true }
          headers = { "X-Scope-OrgID" = "devteam-1" }
        }
      }

      // 2. Logs -> Loki
      otelcol.exporter.loki "loki_shop" {
        forward_to = [loki.write.loki_shop_client.receiver]
      }
      
      loki.write "loki_shop_client" {
        endpoint {
          url = "http://loki-gateway.observability-prd.svc:80/loki/api/v1/push"
          headers = { "X-Scope-OrgID" = "devteam-1" }
        }
      }

      // 3. Metrics -> Mimir (OTLP to Prometheus conversion)
      otelcol.exporter.prometheus "mimir_shop_converter" {
        forward_to = [prometheus.remote_write.mimir_shop.receiver]
      }

      prometheus.remote_write "mimir_shop" {
        endpoint {
          url = "http://mimir-nginx.observability-prd.svc:80/api/v1/push"
          headers = { "X-Scope-OrgID" = "devteam-1" }
        }
      }

# Enable the controller
controller:
  type: daemonset
  # Improve stability for Kubelet scraping
  hostNetwork: true 
  dnsPolicy: ClusterFirstWithHostNet

service:
  enabled: true
  type: ClusterIP
  ports:
    otlp-grpc: { port: 4317, targetPort: 4317, protocol: TCP }
    otlp-http: { port: 4318, targetPort: 4318, protocol: TCP }